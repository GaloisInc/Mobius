\newcommand{\compil}[2]{\overline{#1}^{#2}}

\newcommand{\compilp}[1]{{\cal C}(#1)}


\chapter{Conclusion} 

The work in this task has led to the development of methodologies and
tools that help developers improve the reliability of their code
without affecting their productivity. The tool is integrated in a
widely used developer environment, namely Eclipse, and provides access
to a range of techniques that bring increasing levels of reliability.
The methodology and the tool have been used satisfactorily for a
number of purposes, but should be improved further to enhance its
applicability.

Future work should address limitations of the JML technology, and
increase support for automation, both at the level of specification
and verification. Another major challenge is to capitalize on the 
methodology and tools presented in this document to build a novel
security architecture based on proof-carrying code to support
secure component loading in the context of distributed networks of
Java-enabled TPDs.

\section{Improving the tool and the methodology}
In order to increase the usefulness of the tool, the following
points must be addressed.

\paragraph{Support for reasoning about programs}
Despite having shown its usefulness of a variety of case studies, the
JML technology is still under development, and many technical issues
remain to be solved. For example, JML is currently not appropriate for
reasoning on complex data-structures such as linked-lists or trees
because no global property on these structures can be stated in JML.
This limitation of JML is related to the first-order logic on which
JML is based and that prevents complex quantification over structures
or predicates. Another severe restriction of current JML verification
tools is the limited support they provide for reasoning about
concurrent programs.  There are some ongoing efforts to extend
JML with support for reasoning about multi-threaded programs, but
at the time of writing no practical support has been provided in any tool.


\paragraph{Annotation assistants}
Automated support for annotating programs is of great benefit to allow
program verification to scale to larger programs. Integrating existing
tools that generate specific annotations in JACK would greatly improve
its usefulness. Two lines of work should be pursued independently:
first, one should integrate tools that generate general-purpose
annotations, such as defensive specifications that prevent run-time
exceptions, loop invariants, class invariants or object invariants.
Second, one should pursue the work on generating annotations from 
high-level security properties.

\section{A security architecture for enforcing expressive policies}
We believe that the tool reported in this document could be used as
the basis for a new approach to security, as described in the
following scenario that exploits preservation of proof obligations
(see Section~\ref{pogEquiv}) to bring the benefits of interactive
source program verification to the code consumer. The scenario may be
viewed as an instance of Proof Carrying Code (PCC)~\cite{nec97:popl},
from which it inherits benefits including its robustness under the
code/specification being modified while transiting from producer to
consumer and/or under the assumption of a malicious producer, and
issues including the difficulty of expressing security policies for
applications, etc.

\paragraph*{Proof Carrying Code}
Proof Carrying Code (PCC)~\cite{nec97:popl} is a new approach to
establish trust in a mobile code infrastructure, by requiring that
mobile code is sent along with formal proofs that establish its
correctness.  A typical PCC architecture comprises at least the
following items: a logic, a verification condition generator, a formal
representation of proofs, and a proof checker.


\begin{itemize}
\item\emph{A formal logic for specifying and verifying policies}. The
specification language is used to express requirements on the incoming
program, and the logic is used to verify that the software meets the
expected requirements. For example, requirements can be expressed as pre
and postconditions stating, respectively, conditions to be satisfied
by the state before and after a given procedure or function is
invoked. 

\item\emph{A verification condition generator (VCGen)}. The VCGen
produces, for each program and policy, a set of proof obligations
(POs) which must be discharged to ensure that the program respects the
policy.  In order to make the generation of proof obligations
effective, the VCGen operates on programs annotated with invariants
provided by the code producer or inferred through heuristics.


\item\emph{A formal representation of proofs (Certificates)}.
Certificates provide a formal representation of proofs, and are used
to convey to the code consumer evidence that the code it receives
meets a given policy; different formats, including $\lambda$-terms
have been used in the literature.  One fundamental insight of PCC is
that certificates should be provided by code producers, and then
checked automatically by code consumers.


% By virtue of the Curry-Howard
%isomorphism, certificates may be provided as $\lambda$-terms of a
%suitable type theory, but there is some flexibility in the choice of a
%format for certificates, and different formats have been considered in the
%literature.

\item\emph{A proof checker that validates certificates against
specifications}.  The objective of a proof checker is to verify that
the certificate does indeed establish the proof obligations generated
by the VCGen. The proof checker, like the VCGen, forms part of the
Trusted Computing Base.


%If we use lambda terms as certificates, then proof
%checking is reduced to type checking, so that the proof checker
%verifies that the certificate is of the correct type.  One
%particularly attractive aspect of this approach is that the proof
%checker, which forms part of the Trusted Computing Base, is
%particularly simple.
\end{itemize}
Certificates provide a means to convey evidence to the code consumers,
and are thus an appropriate starting point for our work.
Existing approaches to compilation, such as certifying compilation and
certified compilation, are not designed to transfer evidence from
source programs to target programs, and cannot be used for this
purpose.


\paragraph*{Scenario}\label{subsec:scenario}
Consider a mobile phone operator that is keen of offering its
customers a new service and has the possibility to do so by deploying
a program $\compilp{P}$ originating from an untrusted software
company.  The operator is worried about the negative impact on its
business if the code is malicious or simply erroneous, and wants to 
be given guarantees for $\compilp{P}$. For liability reasons, the
operator does not want to see the source code, and for intellectual
property reasons, the software company does not want to disclose its
source code nor does it authorize the operator to modify the compiled
code to insert additional checks.

The equivalence of proof obligations can be used to justify the
following scenario: the operator provides a partial specification of
the program, e.g.  a precondition $\phi$ and a postcondition $\psi$
for the program {\bf main} procedure, and requires the company to show
that the program meets this partial specification.  There are two
possibilities: either the software company verifies directly
$\compilp{P}$, which is definitely a possibility but not the most
comfortable one, or thanks to preservation of proof obligations, it
can also set to verify $P$, and benefits from the structured nature of
modern programming languages in which we assume that $P$ has been
written. To verify $P$, the software company suitably annotates the
program, leading to an annotated program $P'$.  Then it generates the
set of proof obligations for $P'$ and discharges each proof
obligation using some verification tool that produces proofs. The
compiled annotated program is sent to the operator, together with the
set of proof obligations and their proofs. Upon reception, the
operator checks that the compiled annotated program provided by the
software company matches the partial specification it formulated in
the first place (here it has to check that the precondition and
postcondition are unchanged), and then run its own verification
condition generator, and checks with the help of the proofs provided
by the software company that these proof obligations can be
discharged. 

Our application scenario is being considered for specific application
domains, such as midlets, where operators currently dispose of a large
number of GSM applications that they do not want to distribute to
their customers due to a lack of confidence in the code. Of course, we
do not underestimate that our approach is costly, both by the
infrastructure it requires, and by the effort involved in using it
(notably by involving program verification).  However, the pay-off is
that our approach enables to prove precisely properties of programs,
i.e. in particular correct programs will not be rejected because of
some automatic method which is overly conservative (i.e. rejects
correct programs). 


Our approach can also be used in other mobile code scenarios. Consider
for example a repository of certified algorithms; the algorithms have
been written in different programming languages, but they are stored
in the directory as compiled programs, e.g. as CLR programs. Prior to
adding a new algorithm, say an efficient algorithm to verify square
root, the maintainer of the repository asks for a certificate that the
algorithm indeed computes the square root. The correctness of the
algorithm must be established through interactive verification, say by
the implementer of the algorithm. The implementer has the choice to
write a proof using a program logic for the language in which the
algorithm was developed, or using an appropriate bytecode logic. Once
again, it seems likely that the first approach would be favored, and
therefore that proof obligation preserving compilation would be
useful.


\paragraph{Work to be done}
Much of the PCC infrastructure described above is already present
in our work: the formal logic is provided by BML, the VCGen is the
one implemented by Jack, the formal representation of proofs is
given by the Coq plugin of Jack, and the certificate checker is
given by the Coq type-checker. Future work should aim at exploiting
this infrastructure along the lines of the scenario described above.
