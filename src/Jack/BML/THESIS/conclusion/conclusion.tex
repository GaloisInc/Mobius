
\section{Achievements}
% done. summary
We have  presented an infrastructure for verification of Java bytecode programs   which allows to reason about potentially
sophisticated  functional and security properties and
which benefits from verification over Java source programs. We have also 
introduced the bytecode specification language BML tailored to Java bytecode, a compiler
from the Java source specification language JML to BML and a verification 
condition generator for Java bytecode programs. 
We have shown that the verification procedure is correct w.r.t. a big step  operational semantics of Java bytecode programs. 
Moreover, we have
proven that the verification procedure for Java like programs
and Java like bytecode are syntactically equivalent (modulo names and types). 
%This scheme is actually part of the PCC architecture of the
%European project Mobius\footnote{the site name} which aims to resolve the problems
%of mobile and ubicuous computing via PCC. 
We have developed a prototype of a verification condition generator based on the weakest precondition calculus presented in this thesis, as well 
as a compiler from the corresponding subset of JML to BML.
These two components have been integrated in the JACK \cite{BRL-JACK} verification framework 
developed and supported by our research team Everest at INRIA Sophia Antipolis which has been initially designed for
 the verification of Java source programs annotated with JML specification.

We would like to give a brief description of the implementation of the verification condition generator.
 The extension of the tool to bytecode programs which we added also interfaces these theorem provers. The bytecode 
verification condition generator works as follows. For the verification of a class file containing BML specification, it will generate verification conditions for every
 method of this class including the constructors. For generating the verification conditions concerning a method implementation, first the control flow
 graph corresponding to the bytecode instruction is built. The latter is transformed into an acyclic control flow graph where the backedges are 
removed.
 Then the verification procedure proceeds by generating over every execution path in the control flow graph its corresponding verification conditions. 
For every path which terminates by throwing an uncaught exception, the postcondition is the specified exceptional postcondition for this case. For the paths which terminate normally, 
the normal postcondition is taken. For every path which terminates with an instruction which is dominated by a loop entry and whose direct successor is the same loop entry, the postcondition 
is the corresponding loop invariant. The bytecode verification in Jack uses the intermediate language for the verification conditions and thus, bytecode verification conditions 
 can be translated to several different theorem provers - Simplify \cite{Simpl05DNS} which is an automatic decision procedure, 
the Atelier B and the Coq interactive theorem prover assistants. 

The bytecode verification condition generator benefits also from the original user friendly interface of the JACK tool.  In particular, 
the user can see the verification conditions in his favorite language - Java, Simplify, Coq or B. The lemmas are classified 
to what part of the annotation they refer to, as for instance, a lemma which refers to the establishment of the postcondition, or the preservation of the loop invariant.
The hypothesis in the lemma also hold the index of the instruction from which they originate. 
We have used the prototype of the bytecode verification condition generator for the case studies presented in Chapter \ref{applications:optimComp}.

% JACK (short for Java Applet Correctness Kit) is designed as a plugin for the Java interface development
% environment eclipse. 
%% It was originally tailored to the verification of Java source programs 
%w.r.t. their JML specifications. The tool has an intermediate proof obligation language which allows to extend it easily to interface more 
% theorem provers. Thus, the tool interfaces several theorem provers - Simplify \cite{Simpl05DNS} which is an automatic decision procedure, 
%%the Atelier B and the Coq interactive
%theorem prover assistant. 

\section{Future work}
In the following, we identify the directions for extending the work presented in this thesis

\subsection{Language coverage of the verification condition generator}
The bytecode verification condition generator works only for the sequential fragment of Java. But realistic applications 
rely often on multi - threading which is difficult to verify against a functional specifications or security policies.
One of the important aspects of the correctness of multi - threaded programs is the absence of deadlocks, 
and race conditions. Such properties can be ensured  by type systems \cite{FA99TSL,flanagan00typebased} or static verification based on program logic \cite{FLL02ESC}.  
The absence of deadlock and race conditions is a first step in the verification of the functional correctness of multi threaded programs. In order to build a full 
verification scheme for checking functional correctness more has to be done.
The earliest work for  verification of  parallel programs is  the Owicki and Gries approach   
\cite{nipkow99owickigries}  and the rely - guarantee approach. However, 
the first approach is not modular and requires a large amount of verification conditions while for the second, the annotation procedure can not be automatised.

% Such techniques for reasoning over the correctness of parallel programs  exist.
% One of the first logic - based verification techniques for parallel programs is due to Owicki and Gries 
%\cite{nipkow99owickigries}  in which every point of parallel interference is annotated and then the verification consists in establishing that
% all the possible inter leavings of all the threads respect the annotation. This technique is on one hand not modular as the verification process 
%needs the implementation of every program component and on other hand the number of verification conditions may be very big.
% Another approach is the rely guarantee technique which uses a Hoare style verification conditions \cite{nieto03relyguarantee}.
%There, the program points of interference are annotated not only with the predicate that must hold
%at the point but also with rely and guarantee  conditions which express what conditions the program guarantees to the other threads and what 
%the program requires from the other threads. This technique although tempting because of its modularity and the smaller number of verification conditions is difficult to apply
%as for guessing the rely and guarantee conditions requires an in - depth understanding of the program to be verified.  
Extending our verification scheme for bytecode will certainly be based on a more recent work  where one of the basic concerns is to establish method atomicity  \cite{TES03CF}. 
The notion of a statement atomicity states  that however a statement is interleaved with other parallel programs, the result of its execution will not change.
The atomicity can be  detected via static checking \cite{TES03CF} using type systems. Thus, the program verification process is separated in two parts
- first checking for program atomicity  \cite{TES03CF} are done  
and then verifying the functional correctness using  methodologies for sequential programs as Hoare style reasoning. 
In this last approach in the case of Java, the basic concern is to establish the atomicity of method bodies, i.e. method 
execution does not depend on the possible interleaving with threads.
Recently, E.Rodriguez and al. in \cite{RodriguezDFHLR05} proposed an extension for JML for multi threaded
 programs. Their proposal introduces  new specification keywords which allow to express that a variable is locked or
 that a method is atomic.% Giving the semantics of these keywords is still an ongoing work but we consider that the meaning of these specification constructs does not differ on source and bytecode. 
    
 



\subsection{Property coverage for the specification language}
Another direction which may be pursued as a future work of the thesis  is the extension of the expressiveness of the specification language BML. 
So far, BML supports method contracts - method pre and post  conditions, frame conditions, intermediate annotations as for instance
loop invariants, class specifications as well as special specification operators.
These are very useful aspects which allow for dealing with complex properties and 
gives a semantics on bytecode level  to a relatively small subset of the 
high specification language JML which corresponds to JML Level 0 \footnote{ http://www.cs.iastate.edu/~leavens/JML/jmlrefman/jmlrefman\_2.html\#SEC19}. 
 But it is certainly of interest to support more features of JML in BML
as this will turn the latter language richer. However, the meaning  of JML constructs 
(at least from our experience up to  now) is the same as the meaning of their corresponding part in BML.  

 An important example is the  JML construct for pure methods which has been  identified as  a challenge in the position paper \cite{LeavensLeinoMueller06}. 
 These methods does not modify the program state and thus, pure methods can be used in specifications 
 (only side effect free  expressions may occur in expressions).
 This gives more expressive  specifications as with them, for instance, specification can talk about the result of method invocation or use pure methods
 as a predicate relating their  initial and final state. 
 Formalizing and establishing the meaning of pure methods is difficult and a literature exists for this problem \cite{DarvasMueller06}.
 As we said above, the treatment of pure methods is the same on source and bytecode.

Also, support for specification constructions for alias control is certainly useful  especially because it allows for a modular verification 
of class invariants and frame conditions.
The alias control is guaranteed through ownership type systems which check that only an owner of a reference can modify its contents.
 This can considerably improve the current implementation for the verification of object invariants  \cite{DietlMueller05}.
In particular, our way of proving object invariants is non modular - at every method call the invariants of all visible \todo{say what does it mean visibility}
objects must be valid and they are assumed to hold when the call is terminated; similarly, when a method body is verified in its precondition the invariants of all visible
objects are assumed to hold and at the end of the method body all these invariants must be established. 
In practice, it is very difficult to verify that all the invariants for the all visible objects in a method  hold.
In order to keep the number of the verification conditions reasonable, we check the invariants only for the current object this and the 
objects received as parameters which is not sound.

 
\subsection{Preservation of verification conditions}

So far, we have shown that non-optimizing Java compilation
 preserves the  form of the verification conditions on source and
 bytecode.  We identify two basic directions for future work:
\begin{description}
 \item[Source and non optimized bytecode verification conditions equivalent modulo] % implement the compiler from Java source pogs to bytecode pogs
We have experimented with the verification conditions on source and
 bytecode in JACK and saw that in practice they are almost equivalent
 syntactically. From one part, there are the difference in the types 
 supported on bytecode and source level. For instance, the JVM does not
 provide support for boolean type values which are basically encoded as
 integer values. The same is true for byte and short values.  Another
 difference is the identifiers for variables and fields. For instance, in Java
 names for fields, method local variables and parameters are their identifiers which are given by the
 program developer. On bytecode method local variables and parameters are encoded as elements of the
 method register table and field names are encoded as numbers of the constant
 pool table of the class. A  simple but useful extension to the prototype for
 bytecode verification is a compiler from source proof obligations to bytecode proof obligations
 which overcomes those differences. This can be considered also as a step
 towards the  building a PCC architecture where the certificate generation benefits from
 the source level verification and thus allows for treating sophisticated
 security policies.

\item[Relation between verification conditions on Java source and optimized Java bytecode]
 The equivalence  between verification conditions on source and the corresponding non optimized bytecode is important as it
 allows that bytecode programs  benefit from source verification. In particular, it makes feasible Proof Carrying Code
 for sophisticated client requirements.
 However, a step further in this direction is to investigate the 
 relation between source programs and their bytecode counterpart produced by an optimizing compiler.
 This is interesting for the following reasons.
 It is a fact that interpretation of bytecode on the JVM is slower than execution by its corresponding assembly code. 
 In order to speed up the execution time for a Java bytecode program, one might use 
 a just-in-time compilation which  translates on the fly the bytecode into the machine specific language. However, JIT compilation can potentially slow
 the execution exactly because it does compilation on the fly.  Another possibility is to perform 
 optimizations on the bytecode. Currently, most of the  Java compilers do not support much optimizations.
 However, there do already exist Java optimizing compilers, for instance the Soot optimization framework\footnote{http://www.sable.mcgill.ca/soot/} 
 and most probably the number of the Java optimizing compilers will increase with the evolution of the Java language.
 A first step in the latter direction is the work of C. Kunz et al.\cite{BGKRsas06} who give an algorithm for translating 
 certificates and annotations over a non optimized program into a certificate  and annotation for its optimized version.
 Their work addresses  optimizations like constant propagation, loop induction, dead register elimination etc. 
\end{description}
\subsection{Towards a PCC architecture}

The bytecode verification condition generator and the BML compiler is the first step towards a PCC framework. 
The missing  part is  the certificate format which comes along with the bytecode and which  is the evidence for 
that the bytecode respects the client requirements. Defining an encoding of the certificate should take into account several factors:
\begin{itemize} 
  \item certificate size must be reasonably small. This is important, for instance,  if the certified program comes over a network with a limitted bandwith
  \item certificates must be easily checked. This means that the certificate checker is  small and simple.
	       Of course, the code consumer might not want to spend all of its computation 
	      resources for checking that the certificate guarantees the program conformence to its policies.     
\end{itemize}

Note that the certificate size and its checking complexity are dual: the bigger the certificate is more manageable is the checking process and viceversa. 
The problem becomes even more difficult if the certificate must be checked on the device because of the computational and space constraints.
 


% towards.PCC
% For building a PCC framework from the components cited above 
% % there is still missing the proof certificate, the decision procedure
% that will be used by the producer for the certificate generation and the type checker used by the code
% client for checking the certificate. Important problems in this direction are
% \begin{itemize}
%  \item light weight verification condition generators. In particular, we refer 
%        to verification condition generation techniques which are simple and do not need
%	much computational resources. Because a verification condition generator always
%	form part of the trusted computing base on the client side, building such verification 
%	condition generators is important for on - device checking which rely on limitted computational 
%	resources  
  
%   \item generation of certificates. This is important for several reasons.
%         The certificate may certainly  arrive via the network and should not corrupt the performance 
%  
% 
% %  \item efficient type checker on the client site. This is in particular important 
%         if the device is with limitted resources where a complex certificate checking procedure
%         may corrupt the performance of the device
%        
%     
% \end{itemize}


 %To do this,  it is still missing the proof
%certificate, the decision procedure used by the code producer 
%for building the certificate  as well as the type checker used by the code
%client for checking the certificate. 

% to do. type systems
Another perspective in this direction is how   to encode type systems into the bytecode logic. 
Type systems provide a high level of automation. 
Their encoding in the logic can be useful as the certificate can be generated
 automatically and thus, avoids the user interaction. However, type systems are  conservative in the sense 
that they tend to reject a large amount of correct programs. A possible solution to this problem are hybrid certificates which combine both type systems and program 
logic. In this approach, the unknown code comes supplied with a  derivation in the logic generated potentially with the help of user interaction 
for the parts of the  code which can not be inferred by the type system.   The client side then applies a type inference procedure over  the
 unknown code and once it gets to the place in the parts of the code where the 
type inference does not work but for which there is a derivation in the certificate, he will type check that derivation.   
This is actually an approach which will be adopted in the Mobius project. 


The objective of this thesis was to 
give the basis for the a bytecode verification framework and to show that it is feasible. A further objective, pursued in the European project
 Mobius (short for Ubiquity, Mobility and Security) 
is to build basis for guaranteeing security and trust in program application in the presence of mobile and ubicuous computing. We hope that we have convinced
the reader for the importance of such techniques and in particular of the evolution from source verification to
 low level verification  and the necessity of an interactive verification process for building evidence for the security of unknown applications. 
